import streamlit as st
import google.generativeai as genai
import os
import glob
from gtts import gTTS
import tempfile
import re

# --- CONFIGURATION DE LA PAGE ---
st.set_page_config(page_title="Lex Publica", page_icon="‚öñÔ∏è")
st.title("‚öñÔ∏è Lex Publica | Assistant Juridique")

# --- R√âCUP√âRATION DE LA CL√â API ---
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
else:
    st.error("Cl√© API non configur√©e.")
    st.stop()

# --- PROMPT SYST√àME (VERSION STRICTE TRANSCRIPTION) ---
SYSTEM_PROMPT = """
CONTEXTE : Tu es l'assistant p√©dagogique expert du Professeur Coulibaly.
BASE DE CONNAISSANCES : Strictement limit√©e aux fichiers PDF fournis ("le cours").

R√àGLES ABSOLUES :
1. Si l'√©tudiant pose une question TEXTE : R√©ponds directement avec le cours.
2. Si l'√©tudiant pose une question AUDIO :
   - Ton PREMIER paragraphe doit OBLIGATOIREMENT √™tre : "Vous avez demand√© : [Transcription mot √† mot de la question]"
   - Ton SECOND paragraphe est la r√©ponse bas√©e sur le cours.
3. Ne jamais inventer hors du cours.

TON : Professionnel, encourageant, clair.
"""

# --- FONCTION CHARGEMENT PDF ---
@st.cache_resource
def load_and_process_pdfs():
    pdf_files = glob.glob("*.pdf")
    if not pdf_files:
        return None
    
    uploaded_refs = []
    # On utilise un conteneur vide pour le chargement pour qu'il disparaisse apr√®s
    placeholder = st.empty()
    placeholder.text(f"Chargement de {len(pdf_files)} fichiers de cours...")
    
    try:
        for pdf in pdf_files:
            uploaded_file = genai.upload_file(pdf, mime_type="application/pdf")
            uploaded_refs.append(uploaded_file)
        placeholder.empty() # Hop, on efface le message de chargement
        return uploaded_refs
    except:
        return None

# --- INITIALISATION SESSION ---
if "chat_session" not in st.session_state:
    docs = load_and_process_pdfs()
    if docs:
        model = genai.GenerativeModel(
            model_name="gemini-2.5-flash-lite", 
            system_instruction=SYSTEM_PROMPT
        )
        st.session_state.chat_session = model.start_chat(
            history=[
                {"role": "user", "parts": docs},
                {"role": "model", "parts": ["Je suis pr√™t."]}
            ]
        )
        st.session_state.messages = []
    else:
        st.warning("Veuillez ajouter des PDF sur GitHub.")

# --- BARRE LAT√âRALE ---
with st.sidebar:
    st.header("‚öôÔ∏è Options")
    audio_active = st.toggle("üîä Activer la r√©ponse vocale de l'IA", value=False)
    
    st.divider()
    st.header("üéì Entra√Ænement")
    
    if st.button("üÉè Pose-moi une colle !"):
        if "chat_session" in st.session_state:
            prompt_quiz = "Pose-moi une question de v√©rification sur le cours. Ne donne pas la r√©ponse."
            with st.spinner("Recherche d'une question..."):
                response = st.session_state.chat_session.send_message(prompt_quiz)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                st.rerun()

# --- AFFICHAGE DU CHAT ---
if "messages" in st.session_state:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            # Si le message vient de l'utilisateur et contient l'indicateur sp√©cial
            if message["role"] == "user" and message["content"] == "üé§ *[Question Vocale envoy√©e]*":
                st.markdown("üé§ *Question Vocale envoy√©e*")
            else:
                st.markdown(message["content"])

# --- ZONES DE SAISIE ---
# On met le micro et le texte l'un au-dessus de l'autre
audio_input = st.audio_input("üéôÔ∏è Posez votre question vocalement")
text_input = st.chat_input("... ou √©crivez votre question ici")

user_input = None
is_audio_message = False

if audio_input:
    user_input = audio_input
    is_audio_message = True
elif text_input:
    user_input = text_input
    is_audio_message = False

# --- TRAITEMENT ---
if user_input:
    # 1. On affiche un message PROPRE cot√© √©tudiant (plus de lecteur audio moche)
    if is_audio_message:
        st.session_state.messages.append({"role": "user", "content": "üé§ *[Question Vocale envoy√©e]*"})
        with st.chat_message("user"):
            st.markdown("üé§ *Question Vocale envoy√©e*")
    else:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

    # 2. Envoi √† l'IA
    if "chat_session" in st.session_state:
        with st.chat_message("assistant"):
            with st.spinner("Analyse en cours..."):
                try:
                    if is_audio_message:
                        # Gestion Audio
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_audio:
                            tmp_audio.write(user_input.getvalue())
                            tmp_path = tmp_audio.name
                        
                        uploaded_audio = genai.upload_file(tmp_path, mime_type="audio/wav")
                        
                        # On envoie l'audio avec une consigne simple (le System Prompt fait le reste)
                        response = st.session_state.chat_session.send_message(
                            ["R√©ponds √† cette question orale en suivant tes r√®gles de transcription.", uploaded_audio]
                        )
                    else:
                        # Gestion Texte
                        response = st.session_state.chat_session.send_message(user_input)

                    # Affichage
                    st.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})

                    # Audio IA (si activ√© via le bouton OU si l'√©tudiant a parl√©)
                    if audio_active or is_audio_message:
                        clean_text = re.sub(r'[\*#]', '', response.text)
                        clean_text = re.sub(r'p\.\s*(\d+)', r'page \1', clean_text)
                        clean_text = clean_text.replace("Pr.", "Professeur")
                        
                        tts = gTTS(text=clean_text, lang='fr')
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
                            tts.save(fp.name)
                            st.audio(fp.name, format="audio/mp3")
                            
                except Exception as e:
                    st.error(f"Erreur : {e}")
